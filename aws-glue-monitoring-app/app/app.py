import streamlit as st
import pandas as pd
# import boto3
import streamlit as st
from datetime import datetime
from collections import defaultdict
import json
import os

# acc_id = os.environ.get("AWS_ACCESS_KEY_ID")
# acc_key = os.environ.get("AWS_SECRET_ACCESS_KEY")
###config format {"acc_id": "","acc_key": "","workflow_names": ["wf1","wf2"]}

config_path = os.path.join(os.path.dirname(__file__), "workflow_config.json")
print(config_path)
with open(config_path, "r") as f:
    config = json.load(f)

acc_id = config.get("acc_id", "")
acc_key = config.get("acc_key", "")
workflow_names = config.get("workflow_names", [])


###ìƒ˜í”Œ ë°ì´í„° í…ŒìŠ¤íŠ¸ìš©
workflow_names=["workflow_alpha","workflow_belta"]
sample_path = os.path.join(os.path.dirname(__file__), "workflow_sample.json")
with open(sample_path, "r") as f:
    workflow_sample = json.load(f)['workflow_sample']
def convert_jobruns_datetime(workflow_sample):
    for wf in workflow_sample:
        for run in wf.get('wf_runs', []):
            try:
                run["StartedOn"] = datetime.strptime(run["StartedOn"], "%Y-%m-%d %H:%M:%S")
                run["CompletedOn"] = datetime.strptime(run["CompletedOn"], "%Y-%m-%d %H:%M:%S")
            except Exception:
                run["StartedOn"] = datetime.strptime(run["StartedOn"], "%Y-%m-%d%H:%M:%S")
                run["CompletedOn"] = datetime.strptime(run["CompletedOn"], "%Y-%m-%d%H:%M:%S")
                
            graph = run.get('Graph', {})
            nodes = graph.get('Nodes', [])
            for node in nodes:
                job_details = node.get('JobDetails', {})
                job_runs = job_details.get('JobRuns', [])
                for jr in job_runs:
                    if 'StartedOn' in jr and isinstance(jr['StartedOn'], str):
                        try:
                            jr['StartedOn'] = datetime.strptime(jr['StartedOn'][:19], '%Y-%m-%dT%H:%M:%S')
                        except Exception:
                            jr['StartedOn'] = datetime.strptime(jr['StartedOn'][:19], '%Y-%m-%d%H:%M:%S')
                    if 'CompletedOn' in jr and isinstance(jr['CompletedOn'], str):
                        try:
                            jr['CompletedOn'] = datetime.strptime(jr['CompletedOn'][:19], '%Y-%m-%dT%H:%M:%S')
                        except Exception:
                            jr['CompletedOn'] = datetime.strptime(jr['CompletedOn'][:19], '%Y-%m-%d%H:%M:%S')
    return workflow_sample
workflow_sample = convert_jobruns_datetime(workflow_sample)


STATUS_ICONS = {'Success': 'âœ…','Failed': 'âŒ','Running': 'ğŸ”„','Pending': 'â³','SUCCEEDED': 'âœ…','FAILED': 'âŒ','SKIPPED': 'âšª','RUNNING': 'ğŸ”„','PENDING': 'â³'}
STATUS_COLORS = {'Success': 'green','Failed': 'red','Running': 'orange','Pending': 'grey','SUCCEEDED': 'green','FAILED': 'red','SKIPPED': 'grey','RUNNING': 'orange',
                 'PENDING': 'grey'}

# AWS Glue client
# glue = boto3.client("glue",aws_access_key_id = acc_id,aws_secret_access_key = acc_key,verify=False)

# ì‹¤í–‰ ê²°ê³¼ ìƒì„¸ íŒŒì‹± í•¨ìˆ˜
def get_wf_runs_results(wf_run): 
    if wf_run['Status'] == 'RUNNING':
        wf_run_e_time, wf_run_status, wf_run_t_time = 'WF is still running', 'Running', ''
    else:
        wf_run_status = 'Success' if wf_run['Statistics']['SucceededActions'] == wf_run['Statistics']['TotalActions'] else 'Fail'
        wf_run_t_time = str(wf_run['CompletedOn'] - wf_run['StartedOn']).split('.')[0]
        wf_run_e_time = wf_run['CompletedOn'].strftime('%Y-%m-%d %H:%M:%S')

    # Job ì •ë³´ ì¶”ì¶œ
    result = []
    nodes = wf_run['Graph']['Nodes']
    for node in nodes:
        if node['Type'] == 'JOB':
            if node.get('JobDetails') and node['JobDetails'].get('JobRuns'):
                job_run = node['JobDetails']['JobRuns'][0]
                job_state = job_run.get('JobRunState', 'UNKNOWN')
                job_log = job_run.get('ErrorMessage', 'ì•„ë§ˆ ì„±ê³µ?') if job_state == 'FAILED' else 'ì•„ë§ˆ ì„±ê³µ?'
                job_s_time = job_run.get('StartedOn','UNKNOWN')
                job_e_time = job_run.get('CompletedOn','UNKNOWN')
                job_t_time = job_e_time - job_s_time if job_s_time!='UNKNOWN' and job_e_time!='UNKNOWN' else 'UNKNOWN'
            else:
                job_state = 'NotRun'
                job_log = 'Empty'
                job_s_time = 'UNKNOWN'
                job_e_time = 'UNKNOWN'
                job_t_time = 'UNKNOWN'


            result_dict = {
                'job_name': node['Name'],
                'job_state': job_state,
                'job_log': job_log,
                's_time':job_s_time,
                'e_time':job_e_time,
                't_time': job_t_time
            }
            result.append(result_dict)

    return {
        'wf_name': wf_run['Name'],
        's_time': wf_run['StartedOn'].strftime('%Y-%m-%d %H:%M:%S'),
        'e_time': wf_run_e_time,
        't_time': wf_run_t_time,
        'status': wf_run_status,
        'detail': wf_run['Statistics'],
        'jobs': result,
        'wf_run_id': wf_run['WorkflowRunId']
    }


st.set_page_config(layout="wide")
st.title("AWS Workflow Monitoring Dashboard")

st.sidebar.title("âš™ï¸ Workflow Settings")
# ê³µì§€ì‚¬í•­ ë°•ìŠ¤
st.sidebar.info("""
ğŸ“¢ **ê³µì§€ì‚¬í•­**

- ì›Œí¬í”Œë¡œìš° ë¦¬ìŠ¤íŠ¸ëŠ” **ë‚´ì¥ëœ Config íŒŒì¼**ì„ í†µí•´ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
- Config íŒŒì¼ í¬ë§·ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:

```json
{
  "acc_id": "",
  "acc_key": "",
  "workflow_names": ["wf1", "wf2"]
}
""")

with st.sidebar.form("workflow_form"):
    max_results = st.number_input("Max Workflow Runs to Fetch", min_value=1, max_value=10, value=1)
    #uploaded_file = st.file_uploader("ì›Œí¬í”Œë¡œìš° ê´€ë ¨ íŒŒì¼ ì—…ë¡œë“œ", type=['csv', 'json', 'xlsx'])
    submitted = st.form_submit_button("ğŸš€ Fetch Workflow Runs")

st.markdown("---")

if submitted:
    for workflow_name in workflow_names:
    # for i, workflow_name in enumerate(workflow_names, start=1):
        # renamed_wf_name = f"workflow{i}"
        st.header(f"ğŸ—‚ï¸ Workflow Name: {workflow_name}")  # ì„¹ì…˜ ì œëª©

        workflow_runs = []
        # wf_runs = glue.get_workflow_runs(Name=workflow_name, IncludeGraph=True, MaxResults=max_results)['Runs']
        wf_runs = next((wf for wf in workflow_sample if wf["wf_name"] == workflow_name),None)['wf_runs'][0:max_results]
        
        for wf_run in wf_runs:
            result = get_wf_runs_results(wf_run)

            # result['wf_name'] = renamed_wf_name
            # for j, job in enumerate(result['jobs'], start=1):
            #     job['job_name'] = f"{renamed_wf_name}_job{j}"

            workflow_runs.append(result)
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª©ë¡ì„ ìˆœíšŒí•˜ë©° Expander ìƒì„±
        for run in workflow_runs:
            run_id = run['wf_name']
            status_icon = STATUS_ICONS.get(run['status'], 'â“')
            status_color = STATUS_COLORS.get(run['status'], 'black')
        
            # ì„±ê³µ/ì „ì²´ Job ìˆ˜ ê³„ì‚°
            successful_jobs = sum(1 for job in run['jobs'] if job['job_state'] == 'SUCCEEDED')
            total_jobs = len(run['jobs'])
            success_ratio = f"{successful_jobs} / {total_jobs}"


            # Expander í—¤ë” (ì›Œí¬í”Œë¡œìš° ìš”ì•½ ì •ë³´)
            expander_title = (
                f"{status_icon} run_date: {(run['s_time'])[0:10]}-------------------- Status:{run['status']}--------------------Success/Total: {success_ratio}"
            )

            with st.expander(expander_title, expanded=False):
                st.markdown(f"**Detail Job Execution Records for Workflow Name: `{run_id}`**")
        
                # Job ìƒì„¸ ì •ë³´ë¥¼ ë‹´ì„ DataFrame ìƒì„±
                job_data = []
                for job in run['jobs']:
                    job_status_icon = STATUS_ICONS.get(job['job_state'], 'â“')
                    job_status_color = STATUS_COLORS.get(job['job_state'], 'black')
                    job_name_display = f"<span style='color:{job_status_color};'>â†³ {job['job_name']}</span>"
        
                    job_data.append({
                        'Run ID / Job': job_name_display,
                        'Start Time': job.get('s_time', 'N/A'),
                        'End Time': job.get('e_time', 'N/A'),
                        'Duration': job.get('t_time', 'N/A'),
                        'Status': f"<span style='color:{job_status_color};'>{job_status_icon}</span>",
                    })
                
                df_jobs = pd.DataFrame(job_data)
                
                # HTMLì„ ë Œë”ë§í•˜ê¸° ìœ„í•´ escape=False ì‚¬ìš©
                st.markdown(df_jobs.to_html(escape=False, index=False), unsafe_allow_html=True)

    st.markdown("---")
    st.info("Click on a workflow run to view its detailed job execution records.")
else: 
    st.info("ğŸ“‹ ì„¤ì •ì„ ì™„ë£Œí•œ í›„ 'Fetch Workflow Runs' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
